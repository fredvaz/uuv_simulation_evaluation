#!/usr/bin/env python
# Copyright (c) 2016 The UUV Simulator Authors.
# All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import argparse
import roslib
import rospy
import os
import sys
import yaml
import itertools
import logging
import numpy as np
from time import sleep
from copy import deepcopy
from uuv_simulation_runner import SimulationRunner
from uuv_bag_evaluation import Evaluation
from uuv_cost_function import CostFunction


roslib.load_manifest('uuv_simulation_wrapper')


def parse_input(args, input_map):
    p = vars(args)
    params = dict()
    for tag in input_map:
        if type(input_map[tag]) == list:
            p_cont = list()
            for elem in input_map[tag]:
                if type(elem) == str:
                    p_cont.append(p[elem])
                else:
                    p_cont.append(elem)
        else:
            if type(input_map[tag]) == str:
                p_cont = p[input_map[tag]]
            else:
                p_cont = input_map[tag]
        params[tag] = p_cont

    return params


def has_task_results(output_dir, task_filename):
    results_dir = os.path.join(output_dir, 'results', task_filename.replace('.yml', ''))
    if os.path.isdir(results_dir):
        has_results = False
        for item in os.listdir(results_dir):
            if '.bag' in item or 'process_log' in item:
                print 'Folder <%s> already contains results, skipping...' % results_dir
                has_results = True
        if has_results:
            return True
    return False


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Run batch of simulations')
    parser.add_argument(
        '--task',
        type=str,
        default='task.yml')
    parser.add_argument(
        '--output_dir',
        type=str,
        default='./results')
    parser.add_argument(
        '--config_file',
        type=str,
        default='batch_process_config.yml')

    logger = logging.getLogger('run_batch')
    out_hdlr = logging.StreamHandler(sys.stdout)
    out_hdlr.setFormatter(logging.Formatter('%(asctime)s | %(levelname)s | %(module)s | %(message)s'))
    out_hdlr.setLevel(logging.INFO)
    logger.addHandler(out_hdlr)
    logger.setLevel(logging.INFO)

    # Parse input arguments
    args = parser.parse_args(rospy.myargv()[1:])

    assert os.path.isfile(args.task), 'Task file is not a valid file'
    assert '.yml' in args.task or '.yaml' in args.task, 'Task file is not a YAML file'

    with open(args.task, 'r') as task_file:
        task_config = yaml.load(task_file)

    logger.info('Output directory = ' + args.output_dir)
    if not os.path.isdir(args.output_dir):
        os.makedirs(args.output_dir)
        logger.info('Output directory does not exist, creating <' + args.output_dir + '>')

    output_dir = os.path.abspath(args.output_dir)

    tasks_dir = os.path.join(output_dir, 'tasks')
    if not os.path.isdir(tasks_dir):
        os.makedirs(tasks_dir)
        logger.info('Task configuration directory does not exist, creating <' + tasks_dir + '>')

    # Load optimization configuration
    with open(args.config_file, 'r') as c_file:
        grid_config = yaml.load(c_file)

    assert 'parameters' in grid_config, 'List of input parameters not available'
    assert 'input_map' in grid_config, 'Input parameter map not available'

    # Generate the parameter vectors
    assert type(grid_config) == dict, 'List of parameters must be a dictionary'

    # Copy the input map
    input_map = deepcopy(grid_config['input_map'])

    # Load the cost function
    cost_function = None
    if 'cost_fcn' in grid_config:
        cost_function = CostFunction()
        cost_function.from_dict(grid_config['cost_fcn'])

    time_offset = 0.0
    if 'time_offset' in grid_config:
        time_offset = max(0.0, grid_config['time_offset'])

    # In case the tasks folder is empty, create the tasks
    if len(os.listdir(tasks_dir)) == 0:
        use_monte_carlo = False
        if 'use_monte_carlo' in grid_config:
            use_monte_carlo = grid_config['use_monte_carlo']
        params = dict()
        for tag in grid_config['parameters']:
            param_config = grid_config['parameters'][tag]
            if type(param_config) == list:
                params[tag] = param_config
            elif not use_monte_carlo:
                params[tag] = np.linspace(param_config['min'],
                                          param_config['max'],
                                          param_config['n'])
            else:
                params[tag] = range(param_config['n'])

        counter = 0
        for p in itertools.product(*params.values()):
            temp_task_file = 'task_%d' % counter
            counter += 1
            # Copy the input map
            input_map = deepcopy(grid_config['input_map'])
            # Temporary task configuration
            temp_task = deepcopy(task_config)
            for tag, item in zip(params.keys(), p):
                for param_tag in input_map:
                    if type(input_map[param_tag]) == list:
                        for i in range(len(input_map[param_tag])):
                            if input_map[param_tag][i] == tag:
                                if type(item) == str:
                                    input_map[param_tag][i] = item
                                else:
                                    input_map[param_tag][i] = float(item)
                    else:
                        if input_map[param_tag] == tag:
                            if type(item) == str:
                                input_map[param_tag] = item
                            elif not use_monte_carlo:
                                input_map[param_tag] = float(item)
                            else:
                                input_map[param_tag] = \
                                    float(np.random.random_sample(1)[0] * \
                                    (grid_config['parameters'][tag]['max'] - grid_config['parameters'][tag]['min']) + grid_config['parameters'][tag]['min'])
                                item = input_map[param_tag]
            for tag in input_map:
                temp_task['execute']['params'][tag] = input_map[tag]
            temp_task_file = temp_task_file.replace('.', '-')
            temp_task_file = temp_task_file.replace('/', '-')
            temp_task_file = temp_task_file.replace(':', '-')
            temp_task_file += '.yml'

            temp_task_file_full_path = os.path.join(tasks_dir, temp_task_file)
            if not os.path.isfile(temp_task_file_full_path):
                with open(temp_task_file_full_path, 'w') as gs_file:
                    yaml.dump(temp_task, gs_file, default_flow_style=False)
                logger.info('Task file created=' + os.path.basename(temp_task_file_full_path))
            else:
                logger.info('Task file already exists=' + os.path.basename(temp_task_file_full_path))
    else:
        logger.info('Tasks folder is not empty, using the tasks stored...')

    threads = dict()
    output_sim_file = os.path.join(output_dir, 'analysis.yml')

    # Run simulations
    for task in sorted(os.listdir(tasks_dir)):
        sim_data = dict()
        results_dir = os.path.join(output_dir, 'results', task.replace('.yml', ''))
        if os.path.isdir(results_dir):
            if has_task_results(results_dir, task):
                logger.info('Results for task <%s> already exists, skipping' % task)

        if not has_task_results(output_dir, task):
            try:
                logger.info('Starting simulation...')
                logger.info('\tTask=' + task)
                logger.info('\tResults directory=' + results_dir)
                
                runner = SimulationRunner(dict(),
                                          os.path.join(tasks_dir, task),
                                          results_dir,
                                          True,
                                          add_folder_timestamp=False)

                runner.run(dict())

                logger.info('Start evaluation of the results, task=' + task)
                logger.info('\tTime offset for KPI evaluation[s]=' + str(time_offset))
                logger.info('\tResults files directory=' + runner.current_sim_results_dir)
                logger.info('\tROS bag file=' + runner.recording_filename)
                sim_eval = Evaluation(runner.recording_filename,
                                      runner.current_sim_results_dir,
                                      time_offset=time_offset)

                logger.info('Evaluation finished, task=' + task)

                # Compute KPIs and generate plots from this simulation
                sim_eval.compute_kpis()
                sim_eval.save_evaluation()

                if cost_function is not None:
                    cost_function.set_kpis(sim_eval.get_kpis())

                # Update the batch runs analysis data
                with open(os.path.join(tasks_dir, task), 'r') as task_file:
                    task_data = yaml.load(task_file)

                # Getting the variables set by the batch process from the task
                # files
                for tag in input_map:
                    sim_data[tag] = [task_data['execute']['params'][tag]]

                sim_data['task_file'] = [task]

                if cost_function is not None:
                    sim_data['cost_function'] = [float(cost_function.compute())]

                # Add all KPIs to the output data
                for tag, value in sim_eval.get_kpis().items():
                    sim_data[tag] = [value]
                # Just copy the dictionary of current data if the file
                # does not exist yet
                if not os.path.isfile(output_sim_file):
                    output_sim_data = sim_data
                else:
                    # Update the loaded data from past simulations
                    with open(output_sim_file, 'r') as output_file:
                        output_sim_data = yaml.load(output_file)

                    for tag in sim_data:
                        output_sim_data[tag].append(sim_data[tag][0])

                # Store and overwrite the analysis data
                with open(output_sim_file, 'w+') as output_file:
                    yaml.safe_dump(output_sim_data, output_file,
                                   default_flow_style=False)

                del runner
                del sim_eval
                sleep(0.5)
            except Exception, e:
                logger.error('Error occured while executing task %s' % task)
                logger.error('  Message=' + str(e))
                sleep(0.5)
